# FunASR 故障排除指南

## 问题：模型下载完成后卡住

### 症状

运行 `./scripts/start_funasr.sh` 后：
- ✅ 模型文件下载完成
- ✅ jieba 分词器初始化完成
- ❌ 之后没有输出，看起来卡住了

### 原因

**这是正常现象！** 模型加载到内存需要时间，特别是在 CPU 上：

1. **ASR 模型** (~944MB) 需要加载到内存
2. **VAD 模型** (~1.64MB) 需要加载
3. **标点符号模型** (~1.05GB) 需要加载

在 CPU 上，这个过程可能需要 **2-5 分钟**，期间可能没有输出。

### 解决方案

#### 方案 1：等待（推荐）

**继续等待 2-5 分钟**，应该会看到：
```
✅ 模型加载完成! (耗时: XXX 秒)
✅ 服务器已启动，等待连接...
```

如果超过 10 分钟还没有输出，可能是真的卡住了，尝试方案 2。

#### 方案 2：检查进程

在另一个终端窗口运行：

```bash
# 检查 Python 进程是否在运行
ps aux | grep funasr_server.py

# 检查内存使用（模型加载会占用大量内存）
top -p $(pgrep -f funasr_server.py)
```

如果进程在运行且内存使用在增加，说明正在加载模型，继续等待。

#### 方案 3：使用 GPU（如果可用）

如果有 GPU，可以加快加载速度：

修改 `scripts/funasr_server.py`：

```python
model = AutoModel(
    model="paraformer-zh",
    vad_model="fsmn-vad",
    punc_model="ct-punc",
    device="cuda",  # 改为 cuda（如果有 GPU）
    disable_update=True,
)
```

#### 方案 4：减少模型（如果不需要所有功能）

如果只需要语音识别，可以只加载 ASR 模型：

```python
model = AutoModel(
    model="paraformer-zh",
    # 不加载 VAD 和标点符号模型
    device="cpu",
    disable_update=True,
)
```

### 验证服务器是否启动

等待看到以下输出后，服务器就启动成功了：

```
✅ 模型加载完成! (耗时: XXX 秒)
✅ 服务器已启动，等待连接...
可以在浏览器中连接: ws://localhost:10095
```

### 常见问题

**Q: 为什么加载这么慢？**

A: 模型文件很大（总共约 2GB），需要全部加载到内存。CPU 加载速度较慢，GPU 会快很多。

**Q: 可以加快加载速度吗？**

A: 
- 使用 GPU（如果有）
- 减少加载的模型（如果不需要 VAD 和标点符号）
- 使用更快的 CPU 或更多内存

**Q: 如何知道是否真的卡住了？**

A: 
- 检查进程是否在运行：`ps aux | grep funasr`
- 检查内存使用是否在增加
- 如果超过 10 分钟且内存不再增加，可能是卡住了

**Q: 卡住了怎么办？**

A: 
1. 按 `Ctrl+C` 停止
2. 检查错误日志
3. 尝试重启
4. 如果持续卡住，检查系统资源（内存、磁盘空间）

### 性能参考

| 设备 | 加载时间 | 说明 |
|------|---------|------|
| CPU (普通) | 2-5 分钟 | 正常情况 |
| CPU (高性能) | 1-3 分钟 | 更快 |
| GPU | 30-60 秒 | 最快 |

### 下一步

服务器启动后，可以：
1. 在前端测试语音识别功能
2. 查看服务器日志确认连接
3. 开始使用 FunASR 进行语音识别
